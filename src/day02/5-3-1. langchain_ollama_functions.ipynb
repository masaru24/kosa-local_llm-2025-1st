{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain[ollama] langchain[community]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e770e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def power(a: int, b: int) -> int:\n",
    "    \"\"\"Return a to the power of b \"\"\"\n",
    "    return a ** b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124b991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run-fa405cda-47bf-4c28-81d7-4e4b387fe4e0-0' tool_calls=[{'name': 'directly-answer', 'args': {}, 'id': '33de724e-bf86-4adb-aa89-878cd1292529', 'type': 'tool_call'}]\n",
      "content='' additional_kwargs={} response_metadata={} id='run-390bd53f-c753-4c7b-8b89-e736e8883ee3-0' tool_calls=[{'name': 'power', 'args': {'a': 2, 'b': 100}, 'id': 'a344e389-e828-4cd7-9239-6a8b513a9bbb', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "llm = ChatOllama(model=os.getenv(\"OPENAI_DEFAULT_MODEL\"), format=\"json\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools=[add, multiply, power])\n",
    "\n",
    "response = llm_with_tools.invoke(\"안녕?\")\n",
    "print(response)\n",
    "\n",
    "query = \"2의 100승은?\"\n",
    "response = llm_with_tools.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cd25c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='2의 100승은?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={}, id='run-4acf4f20-39d0-423c-974f-4df1d5712daa-0', tool_calls=[{'name': 'power', 'args': {'a': 2, 'b': 100}, 'id': '3ccb235b-0cec-47b7-91a2-8f98b0e57b03', 'type': 'tool_call'}]), FunctionMessage(content='1267650600228229401496703205376', additional_kwargs={}, response_metadata={}, name='power')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, FunctionMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply, \"power\": power}[tool_call[\"name\"].lower()]\n",
    "    tool_output = str(selected_tool.invoke(tool_call[\"args\"]))\n",
    "    messages.append(FunctionMessage(tool_output, name=tool_call[\"name\"]))\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18af526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51097/1621789022.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  Ollama(model=os.getenv(\"OPENAI_DEFAULT_MODEL\"), temperature=0).invoke(messages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신이 묻는 것은 2의 100제곱에 대한 계산입니다. 이는 2를 100번 곱하는 것을 의미합니다. 결과는 다음과 같습니다:\\n\\n2의 100승 = 2^100 = 1267650600228229401496703205376'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import os\n",
    "\n",
    "Ollama(model=os.getenv(\"OPENAI_DEFAULT_MODEL\"), temperature=0).invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38dfeff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23의 17승은 약 1.41 x 10^258입니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def process_query(query):\n",
    "    messages = []\n",
    "    ai_msg = llm_with_tools.invoke(query)\n",
    "    messages.append(ai_msg)\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        selected_tool = {\"add\": add, \"multiply\": multiply, \"power\": power }[tool_call[\"name\"].lower()]\n",
    "        tool_output = str(selected_tool.invoke(tool_call[\"args\"]))\n",
    "        messages.append(FunctionMessage(tool_output, name=tool_call[\"name\"]))   \n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_template(\"\"\"다음 내용에 근거하여 질문에 간단히 한국어로 답하세요:\n",
    "                                                {context}\n",
    "                                                \n",
    "                                                Question:{question}\n",
    "                                                Answer:\"\"\")\n",
    "    chat_model = ChatOllama(model=os.getenv(\"OPENAI_DEFAULT_MODEL\"), temperature=0)\n",
    "    llm_chain = chat_prompt | chat_model| StrOutputParser()\n",
    "    response = llm_chain.invoke({\"context\":messages, \"question\":query})\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return \"No response found.\"\n",
    "\n",
    "query = \"23의 17승은 얼마입니까?\"\n",
    "process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888084c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
